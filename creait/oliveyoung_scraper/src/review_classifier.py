"""ë¦¬ë·° ë¶„ë¥˜ ë° ì¥ë‹¨ì  ì¶”ì¶œ ì‹œìŠ¤í…œ"""
import os
import json
from typing import Dict, List, Optional
from loguru import logger
from openai import AsyncOpenAI
from dotenv import load_dotenv

from .database import get_product_reviews_by_rating, save_review_analysis, get_review_analysis_results

load_dotenv()

class ReviewClassifier:
    """ë¦¬ë·°ë¥¼ ë³„ì ë³„ë¡œ ë¶„ë¥˜í•˜ê³  ì†Œë¹„ì ê·¼ê±°ë¥¼ ë³´ì¡´í•˜ë©° ì¥ë‹¨ì ì„ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ReviewClassifier ì´ˆê¸°í™”"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        self.client = AsyncOpenAI(api_key=api_key)
        logger.info("ReviewClassifier ì´ˆê¸°í™” ì™„ë£Œ")
    
    def classify_reviews_by_rating(self, product_id: int) -> Dict[str, List[str]]:
        """
        ì œí’ˆì˜ ë¦¬ë·°ë¥¼ ë³„ì  ê¸°ì¤€ìœ¼ë¡œ 3ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜
        
        Args:
            product_id: ë¶„ë¥˜í•  ì œí’ˆ ID
            
        Returns:
            ë¶„ë¥˜ëœ ë¦¬ë·° ë”•ì…”ë„ˆë¦¬ {'positive_5': [...], 'neutral_4_3': [...], 'negative_2_1': [...]}
        """
        try:
            logger.info(f"ì œí’ˆ ID {product_id}ì˜ ë¦¬ë·° ë¶„ë¥˜ ì‹œì‘")
            classified_reviews = get_product_reviews_by_rating(product_id)
            
            logger.info(f"ë¶„ë¥˜ ê²°ê³¼: ê¸ì • {len(classified_reviews['positive_5'])}ê°œ, "
                       f"ì¤‘ë¦½ {len(classified_reviews['neutral_4_3'])}ê°œ, "
                       f"ë¶€ì • {len(classified_reviews['negative_2_1'])}ê°œ")
            
            return classified_reviews
            
        except Exception as e:
            logger.error(f"ë¦¬ë·° ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'positive_5': [], 'neutral_4_3': [], 'negative_2_1': []}
    
    async def extract_insights_with_evidence(self, reviews: List[str], sentiment_group: str) -> Dict[str, any]:
        """
        ì†Œë¹„ì ê·¼ê±°ë¥¼ ë³´ì¡´í•˜ë©° ì¥ë‹¨ì  ì¶”ì¶œ (í† í° ì œí•œì„ ê³ ë ¤í•œ ì²­í¬ ê¸°ë°˜ ì²˜ë¦¬)
        
        Args:
            reviews: ë¶„ì„í•  ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            sentiment_group: ê°ì • ê·¸ë£¹ ('positive_5', 'neutral_4_3', 'negative_2_1')
            
        Returns:
            ì¥ë‹¨ì ê³¼ ê·¼ê±°ê°€ í¬í•¨ëœ ë¶„ì„ ê²°ê³¼
        """
        if not reviews:
            logger.warning(f"{sentiment_group} ê·¸ë£¹ì— ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"advantages": [], "disadvantages": []}
        
        try:
            logger.info(f"{sentiment_group} ê·¸ë£¹ {len(reviews)}ê°œ ë¦¬ë·° ë¶„ì„ ì‹œì‘")
            
            # í† í° ì œí•œ ê³ ë ¤: ë¦¬ë·°ê°€ 100ê°œ ì´ìƒì´ë©´ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
            if len(reviews) > 100:
                logger.info(f"{sentiment_group} ê·¸ë£¹: ë¦¬ë·°ê°€ {len(reviews)}ê°œë¡œ ë§ì•„ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í•  ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                return await self._process_reviews_in_chunks(reviews, sentiment_group)
            else:
                # ê¸°ì¡´ ë°©ì‹: ëª¨ë“  ë¦¬ë·°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
                return await self._process_single_chunk(reviews, sentiment_group, 0)
            
        except Exception as e:
            logger.error(f"{sentiment_group} ê·¸ë£¹ ì¥ë‹¨ì  ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"advantages": [], "disadvantages": []}
    
    async def _process_reviews_in_chunks(self, reviews: List[str], sentiment_group: str) -> Dict[str, any]:
        """
        ë¦¬ë·°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ í†µí•©
        
        Args:
            reviews: ë¶„ì„í•  ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            sentiment_group: ê°ì • ê·¸ë£¹
            
        Returns:
            í†µí•©ëœ ë¶„ì„ ê²°ê³¼
        """
        chunk_size = 80  # ì²­í¬ë‹¹ ë¦¬ë·° ê°œìˆ˜ (í† í° ì œí•œ ê³ ë ¤)
        chunks = [reviews[i:i+chunk_size] for i in range(0, len(reviews), chunk_size)]
        
        logger.info(f"{sentiment_group} ê·¸ë£¹: {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬")
        
        all_advantages = []
        all_disadvantages = []
        
        for i, chunk in enumerate(chunks):
            logger.info(f"{sentiment_group} ê·¸ë£¹: ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... ({len(chunk)}ê°œ ë¦¬ë·°)")
            
            try:
                chunk_result = await self._process_single_chunk(chunk, sentiment_group, i * chunk_size)
                
                # ê° ì²­í¬ì˜ ê²°ê³¼ë¥¼ í†µí•©
                if chunk_result.get("advantages"):
                    all_advantages.extend(chunk_result["advantages"])
                if chunk_result.get("disadvantages"):
                    all_disadvantages.extend(chunk_result["disadvantages"])
                    
                logger.info(f"{sentiment_group} ê·¸ë£¹: ì²­í¬ {i+1} ì™„ë£Œ - ì¥ì  {len(chunk_result.get('advantages', []))}ê°œ, ë‹¨ì  {len(chunk_result.get('disadvantages', []))}ê°œ")
                
            except Exception as e:
                logger.error(f"{sentiment_group} ê·¸ë£¹: ì²­í¬ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ìµœì¢… í†µí•© ê²°ê³¼
        final_result = {
            "advantages": all_advantages,
            "disadvantages": all_disadvantages
        }
        
        logger.info(f"{sentiment_group} ê·¸ë£¹: ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ - ìµœì¢… ì¥ì  {len(all_advantages)}ê°œ, ë‹¨ì  {len(all_disadvantages)}ê°œ")
        return final_result
    
    async def _process_single_chunk(self, reviews: List[str], sentiment_group: str, offset: int = 0) -> Dict[str, any]:
        """
        ë‹¨ì¼ ì²­í¬ì˜ ë¦¬ë·°ë“¤ì„ ì²˜ë¦¬
        
        Args:
            reviews: ì²˜ë¦¬í•  ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
            sentiment_group: ê°ì • ê·¸ë£¹
            offset: ë¦¬ë·° ë²ˆí˜¸ ì˜¤í”„ì…‹ (ì²­í¬ ì²˜ë¦¬ ì‹œ ì „ì²´ ë²ˆí˜¸ ìœ ì§€ìš©)
            
        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        # ëª¨ë“  ë¦¬ë·°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (ë²ˆí˜¸ ë§¤ê¸°ê¸°)
        numbered_reviews = []
        for i, review in enumerate(reviews, 1 + offset):
            numbered_reviews.append(f"[ë¦¬ë·° {i}] {review}")
        
        combined_reviews = "\n\n".join(numbered_reviews)
        
        prompt = self._get_analysis_prompt(sentiment_group)
        
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": f"ë‹¤ìŒì€ {sentiment_group} ê·¸ë£¹ì˜ ë¦¬ë·°ì…ë‹ˆë‹¤:\n\n{combined_reviews}"}
            ],
            temperature=0.0,
            max_tokens=3000,
            response_format={"type": "json_object"}
        )
        
        result = response.choices[0].message.content.strip()
        
        # JSON ì¶”ì¶œ ë° íŒŒì‹± ì‹œë„
        try:
            # 1ì°¨: ì§ì ‘ JSON íŒŒì‹± ì‹œë„
            parsed_result = json.loads(result)
            return parsed_result
        except json.JSONDecodeError:
            # 2ì°¨: JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            try:
                # ```json ë¸”ë¡ì—ì„œ ì¶”ì¶œ
                if "```json" in result:
                    json_start = result.find("```json") + 7
                    json_end = result.find("```", json_start)
                    if json_end != -1:
                        json_content = result[json_start:json_end].strip()
                        parsed_result = json.loads(json_content)
                        return parsed_result
                
                # { ì™€ } ì‚¬ì´ì˜ JSON ì¶”ì¶œ
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                if json_start != -1 and json_end > json_start:
                    json_content = result[json_start:json_end]
                    parsed_result = json.loads(json_content)
                    return parsed_result
                    
                logger.warning(f"{sentiment_group} ì²­í¬: JSON ì¶”ì¶œ ì‹¤íŒ¨, ì›ë³¸ ë‚´ìš© ì¼ë¶€: {result[:200]}...")
                return {"advantages": [], "disadvantages": []}
                    
            except json.JSONDecodeError as e:
                logger.warning(f"{sentiment_group} ì²­í¬: JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")
                logger.warning(f"ì¶”ì¶œ ì‹œë„í•œ ë‚´ìš©: {result[:500]}...")
                return {"advantages": [], "disadvantages": []}
    
    def _get_analysis_prompt(self, sentiment_group: str) -> str:
        """ê°ì • ê·¸ë£¹ì— ë§ëŠ” ë¶„ì„ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        
        base_instruction = """ë‹¹ì‹ ì€ í™”ì¥í’ˆ ë° ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì†Œë¹„ì ë¦¬ë·°ë“¤ì„ ë¶„ì„í•˜ì—¬ ì œí’ˆì˜ êµ¬ì²´ì ì¸ ì¥ì ê³¼ ë‹¨ì ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ğŸ”´ ì¤‘ìš” ìš”êµ¬ì‚¬í•­:
1. ëª¨ë“  ë¦¬ë·° ë‚´ìš©ì´ ë¶„ì„ ê²°ê³¼ì— ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ (ì •ë³´ ì†ì‹¤ ë°©ì§€)
2. ê° ì¥ì /ë‹¨ì ë§ˆë‹¤ í•´ë‹¹ ë‚´ìš©ì„ ì–¸ê¸‰í•œ ë¦¬ë·° ë²ˆí˜¸ë¥¼ ì •í™•íˆ ê¸°ë¡í•´ì£¼ì„¸ìš”
3. ì†Œë¹„ìë“¤ì˜ ì›ë¬¸ í‘œí˜„ì„ ìµœëŒ€í•œ ë³´ì¡´í•´ì£¼ì„¸ìš”
4. ìš”ì•½í•˜ì§€ ë§ê³  êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ëª¨ë‘ í¬í•¨í•´ì£¼ì„¸ìš”

ğŸ’¡ ì‘ë‹µ í˜•ì‹: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""
        
        if sentiment_group == "positive_5":
            specific_instruction = """
ì´ ê·¸ë£¹ì€ 5ì  ë§Œì  ë¦¬ë·°ë“¤ì…ë‹ˆë‹¤. ì£¼ë¡œ ì¥ì ì„ ì°¾ë˜, ì•„ì‰¬ìš´ ì ì´ë‚˜ ê°œì„ ì ë„ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”."""
        elif sentiment_group == "neutral_4_3":
            specific_instruction = """
ì´ ê·¸ë£¹ì€ 4-3ì  ë¦¬ë·°ë“¤ì…ë‹ˆë‹¤. ì¥ì ê³¼ ë‹¨ì ì´ ê· í˜•ìˆê²Œ ì–¸ê¸‰ë  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."""
        else:  # negative_2_1
            specific_instruction = """
ì´ ê·¸ë£¹ì€ 2-1ì  ë¦¬ë·°ë“¤ì…ë‹ˆë‹¤. ì£¼ë¡œ ë‹¨ì ì„ ì°¾ë˜, ê¸ì •ì ì¸ ì¸¡ë©´ë„ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”."""
        
        json_format = """{
    "advantages": [
        {
            "point": "êµ¬ì²´ì ì¸ ì¥ì  (ì†Œë¹„ì í‘œí˜„ ê·¸ëŒ€ë¡œ)",
            "evidence": ["ê´€ë ¨ ë¦¬ë·° ë²ˆí˜¸ë“¤"],
            "details": "í•´ë‹¹ ì¥ì ì— ëŒ€í•œ ëª¨ë“  ì„¸ë¶€ ë‚´ìš©"
        }
    ],
    "disadvantages": [
        {
            "point": "êµ¬ì²´ì ì¸ ë‹¨ì  (ì†Œë¹„ì í‘œí˜„ ê·¸ëŒ€ë¡œ)",
            "evidence": ["ê´€ë ¨ ë¦¬ë·° ë²ˆí˜¸ë“¤"],
            "details": "í•´ë‹¹ ë‹¨ì ì— ëŒ€í•œ ëª¨ë“  ì„¸ë¶€ ë‚´ìš©"
        }
    ]
}"""
        
        return f"""{base_instruction}

{specific_instruction}

ğŸ”¥ ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
{json_format}

âš ï¸ ëª¨ë“  ë¦¬ë·°ì˜ ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ advantages ë˜ëŠ” disadvantagesì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°: ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""
    
    async def analyze_product_reviews(self, product_id: int) -> Dict[str, any]:
        """
        ì œí’ˆì˜ ì „ì²´ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ ê°ì •ë³„ ì¥ë‹¨ì  ì¶”ì¶œ
        
        Args:
            product_id: ë¶„ì„í•  ì œí’ˆ ID
            
        Returns:
            ì „ì²´ ë¶„ì„ ê²°ê³¼
        """
        try:
            logger.info(f"ì œí’ˆ ID {product_id} ì „ì²´ ë¦¬ë·° ë¶„ì„ ì‹œì‘")
            
            # 1. ë¦¬ë·° ë¶„ë¥˜
            classified_reviews = self.classify_reviews_by_rating(product_id)
            
            # 2. ê° ê·¸ë£¹ë³„ ì¥ë‹¨ì  ë¶„ì„
            analysis_results = {}
            
            for group_name, reviews in classified_reviews.items():
                if reviews:  # ë¦¬ë·°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë¶„ì„
                    logger.info(f"{group_name} ê·¸ë£¹ ë¶„ì„ ì¤‘...")
                    group_analysis = await self.extract_insights_with_evidence(reviews, group_name)
                    analysis_results[group_name] = {
                        "review_count": len(reviews),
                        "analysis": group_analysis
                    }
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    advantages_json = json.dumps(group_analysis.get("advantages", []), ensure_ascii=False)
                    disadvantages_json = json.dumps(group_analysis.get("disadvantages", []), ensure_ascii=False)
                    
                    save_success = save_review_analysis(
                        product_id=product_id,
                        sentiment_group=group_name,
                        advantages=advantages_json,
                        disadvantages=disadvantages_json,
                        review_count=len(reviews)
                    )
                    
                    if save_success:
                        logger.info(f"{group_name} ê·¸ë£¹ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
                    else:
                        logger.error(f"{group_name} ê·¸ë£¹ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")
                else:
                    logger.info(f"{group_name} ê·¸ë£¹ì— ë¦¬ë·°ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                    analysis_results[group_name] = {
                        "review_count": 0,
                        "analysis": {"advantages": [], "disadvantages": []}
                    }
            
            logger.info(f"ì œí’ˆ ID {product_id} ì „ì²´ ë¦¬ë·° ë¶„ì„ ì™„ë£Œ")
            return analysis_results
            
        except Exception as e:
            logger.error(f"ì œí’ˆ ë¦¬ë·° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    async def get_analysis_stats(self) -> Dict[str, any]:
        """ë¦¬ë·° ë¶„ì„ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            from .database import DB_FILE
            import sqlite3
            
            con = sqlite3.connect(DB_FILE)
            cur = con.cursor()
            
            # ì „ì²´ ì œí’ˆ ìˆ˜
            cur.execute("SELECT COUNT(*) FROM products")
            total_products = cur.fetchone()[0]
            
            # ë¶„ì„ ì™„ë£Œëœ ì œí’ˆ ìˆ˜ (3ê°œ ê·¸ë£¹ ëª¨ë‘ ë¶„ì„ëœ ì œí’ˆ)
            cur.execute("""
                SELECT COUNT(DISTINCT product_id) 
                FROM review_analysis
            """)
            analyzed_products = cur.fetchone()[0]
            
            # ê·¸ë£¹ë³„ ë¶„ì„ í†µê³„
            cur.execute("""
                SELECT sentiment_group, COUNT(*), SUM(review_count)
                FROM review_analysis
                GROUP BY sentiment_group
            """)
            group_stats = cur.fetchall()
            
            con.close()
            
            completion_rate = (analyzed_products / total_products * 100) if total_products > 0 else 0
            
            stats = {
                "total_products": total_products,
                "analyzed_products": analyzed_products,
                "completion_rate": f"{completion_rate:.1f}%",
                "group_analysis": {}
            }
            
            for group, count, total_reviews in group_stats:
                stats["group_analysis"][group] = {
                    "analyzed_products": count,
                    "total_reviews": total_reviews
                }
            
            return stats
            
        except Exception as e:
            logger.error(f"ë¶„ì„ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}

    def get_product_analysis_summary(self, product_id: int) -> Optional[Dict]:
        """íŠ¹ì • ì œí’ˆì˜ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¡°íšŒ"""
        try:
            results = get_review_analysis_results(product_id)
            
            if not results:
                return None
            
            summary = {
                "product_id": product_id,
                "product_name": results[0][1],  # ì²« ë²ˆì§¸ ê²°ê³¼ì—ì„œ ì œí’ˆëª… ì¶”ì¶œ
                "analysis_groups": {}
            }
            
            for result in results:
                _, _, sentiment_group, advantages, disadvantages, review_count, analyzed_at = result
                
                try:
                    advantages_parsed = json.loads(advantages) if advantages else []
                    disadvantages_parsed = json.loads(disadvantages) if disadvantages else []
                except json.JSONDecodeError:
                    advantages_parsed = []
                    disadvantages_parsed = []
                
                summary["analysis_groups"][sentiment_group] = {
                    "review_count": review_count,
                    "advantages_count": len(advantages_parsed),
                    "disadvantages_count": len(disadvantages_parsed),
                    "analyzed_at": analyzed_at
                }
            
            return summary
            
        except Exception as e:
            logger.error(f"ì œí’ˆ ë¶„ì„ ìš”ì•½ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return None