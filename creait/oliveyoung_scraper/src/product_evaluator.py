"""ì œí’ˆ í‰ê°€ ì‹œìŠ¤í…œ - ê°€ì¤‘í‰ê·  + ëª¨ìˆœ íƒì§€ ê¸°ë°˜ ì ìˆ˜ ì°¨ê°"""
import os
import json
from typing import Dict, List, Optional, Tuple
from loguru import logger
from openai import AsyncOpenAI
from dotenv import load_dotenv

from .database import (
    get_product_review_ratings, 
    get_review_analysis_results,
    save_product_evaluation,
    get_product_evaluation,
    get_all_product_evaluations
)

load_dotenv()

class ProductEvaluator:
    """ì œí’ˆì„ ê°€ì¤‘í‰ê· ê³¼ ëª¨ìˆœ íƒì§€ë¥¼ í†µí•´ ì¢…í•© í‰ê°€í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ProductEvaluator ì´ˆê¸°í™”"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        self.client = AsyncOpenAI(api_key=api_key)
        
        # ê°€ì¤‘ì¹˜ ì„¤ì • (ë¶€ì • ë¦¬ë·° ê°•í™”)
        self.rating_weights = {
            5: 1.0,   # 5ì : ê¸°ë³¸ ê°€ì¤‘ì¹˜
            4: 0.8,   # 4ì : ì•½ê°„ ê°ì†Œ
            3: 0.6,   # 3ì : ë” ê°ì†Œ
            2: 2.0,   # 2ì : ë¶€ì • ë¦¬ë·° ê°•í™” (2ë°°)
            1: 2.0,   # 1ì : ë¶€ì • ë¦¬ë·° ê°•í™” (2ë°°)
        }
        
        logger.info("ProductEvaluator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def calculate_weighted_score(self, product_id: int) -> Tuple[float, Dict]:
        """
        ì œí’ˆì˜ ê°€ì¤‘í‰ê·  ì ìˆ˜ ê³„ì‚° (ë¶€ì • ë¦¬ë·° ê°•í™”)
        
        Args:
            product_id: í‰ê°€í•  ì œí’ˆ ID
            
        Returns:
            (ê°€ì¤‘í‰ê·  ì ìˆ˜, ê³„ì‚° ìƒì„¸ì •ë³´)
        """
        try:
            logger.info(f"ì œí’ˆ ID {product_id}ì˜ ê°€ì¤‘í‰ê·  ì ìˆ˜ ê³„ì‚° ì‹œì‘")
            
            # ë¦¬ë·° ë³„ì  ë¶„í¬ ê°€ì ¸ì˜¤ê¸°
            rating_distribution = get_product_review_ratings(product_id)
            
            if not rating_distribution:
                logger.warning(f"ì œí’ˆ ID {product_id}ì— ëŒ€í•œ ë¦¬ë·° ë³„ì ì´ ì—†ìŠµë‹ˆë‹¤.")
                return 0.0, {"error": "ë¦¬ë·° ë°ì´í„° ì—†ìŒ"}
            
            weighted_sum = 0.0
            weight_sum = 0.0
            calculation_details = {
                "rating_distribution": {},
                "calculations": [],
                "total_reviews": 0
            }
            
            total_reviews = 0
            
            for rating_str, count in rating_distribution:
                try:
                    rating = int(rating_str)
                    weight = self.rating_weights.get(rating, 1.0)
                    
                    contribution = rating * count * weight
                    weighted_sum += contribution
                    weight_sum += count * weight
                    total_reviews += count
                    
                    calculation_details["rating_distribution"][rating] = count
                    calculation_details["calculations"].append({
                        "rating": rating,
                        "count": count,
                        "weight": weight,
                        "contribution": contribution
                    })
                    
                    logger.debug(f"{rating}ì  x {count}ê°œ x {weight} = {contribution}")
                    
                except (ValueError, TypeError):
                    logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ë³„ì : {rating_str}")
                    continue
            
            if weight_sum == 0:
                logger.error(f"ì œí’ˆ ID {product_id}ì˜ ê°€ì¤‘ì¹˜ í•©ì´ 0ì…ë‹ˆë‹¤.")
                return 0.0, {"error": "ê°€ì¤‘ì¹˜ ê³„ì‚° ì˜¤ë¥˜"}
            
            weighted_average = weighted_sum / weight_sum
            
            calculation_details["total_reviews"] = total_reviews
            calculation_details["weighted_sum"] = weighted_sum
            calculation_details["weight_sum"] = weight_sum
            calculation_details["weighted_average"] = weighted_average
            
            logger.info(f"ì œí’ˆ ID {product_id} ê°€ì¤‘í‰ê· : {weighted_average:.2f}/5.0 (ì´ {total_reviews}ê°œ ë¦¬ë·°)")
            
            return weighted_average, calculation_details
            
        except Exception as e:
            logger.error(f"ê°€ì¤‘í‰ê·  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.0, {"error": str(e)}
    
    async def detect_contradictions(self, product_id: int) -> Tuple[List[Dict], float]:
        """
        ìƒì„¸ì •ë³´ì™€ ë¦¬ë·° ê°„ ëª¨ìˆœ íƒì§€ ë° ì ìˆ˜ ì°¨ê° ê³„ì‚°
        
        Args:
            product_id: ë¶„ì„í•  ì œí’ˆ ID
            
        Returns:
            (ëª¨ìˆœ ëª©ë¡, ì°¨ê° ì ìˆ˜)
        """
        try:
            logger.info(f"ì œí’ˆ ID {product_id}ì˜ ëª¨ìˆœ íƒì§€ ì‹œì‘")
            
            # ìƒì„¸ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            from .database import DB_FILE
            import sqlite3
            
            con = sqlite3.connect(DB_FILE)
            cur = con.cursor()
            
            cur.execute("SELECT detailed_summary FROM products WHERE id = ?", (product_id,))
            summary_result = cur.fetchone()
            
            if not summary_result or not summary_result[0]:
                con.close()
                logger.warning(f"ì œí’ˆ ID {product_id}ì˜ ìƒì„¸ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return [], 0.0
            
            detailed_summary = summary_result[0]
            con.close()
            
            # ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            review_analysis = get_review_analysis_results(product_id)
            
            if not review_analysis:
                logger.warning(f"ì œí’ˆ ID {product_id}ì˜ ë¦¬ë·° ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return [], 0.0
            
            # ë¦¬ë·° ë¶„ì„ ë°ì´í„°ë¥¼ ê·¸ë£¹ë³„ë¡œ ì •ë¦¬
            review_groups = {}
            for result in review_analysis:
                _, _, sentiment_group, advantages, disadvantages, review_count, _ = result
                
                try:
                    advantages_parsed = json.loads(advantages) if advantages else []
                    disadvantages_parsed = json.loads(disadvantages) if disadvantages else []
                except json.JSONDecodeError:
                    advantages_parsed = []
                    disadvantages_parsed = []
                
                review_groups[sentiment_group] = {
                    "advantages": advantages_parsed,
                    "disadvantages": disadvantages_parsed,
                    "review_count": review_count
                }
            
            # AIë¥¼ í†µí•œ ëª¨ìˆœ íƒì§€
            contradictions = await self._analyze_contradictions_with_ai(detailed_summary, review_groups)
            
            # ì°¨ê° ì ìˆ˜ ê³„ì‚°
            penalty_score = self._calculate_penalty_score(contradictions)
            
            logger.info(f"ì œí’ˆ ID {product_id} ëª¨ìˆœ íƒì§€ ì™„ë£Œ: {len(contradictions)}ê°œ ëª¨ìˆœ, -{penalty_score:.2f}ì  ì°¨ê°")
            
            return contradictions, penalty_score
            
        except Exception as e:
            logger.error(f"ëª¨ìˆœ íƒì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            return [], 0.0
    
    async def _analyze_contradictions_with_ai(self, detailed_summary: str, review_groups: Dict) -> List[Dict]:
        """AIë¥¼ í†µí•œ ìƒì„¸ì •ë³´-ë¦¬ë·° ê°„ ëª¨ìˆœ ë¶„ì„"""
        try:
            prompt = self._get_contradiction_analysis_prompt()
            
            # ë¦¬ë·° ê·¸ë£¹ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            review_summary = self._format_review_groups_for_analysis(review_groups)
            
            user_message = f"""
ìƒì„¸ì •ë³´:
{detailed_summary}

ë¦¬ë·° ë¶„ì„ ê²°ê³¼:
{review_summary}
"""
            
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.0,
                max_tokens=1500
            )
            
            result = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed_result = json.loads(result)
                contradictions = parsed_result.get("contradictions", [])
                logger.info(f"AI ëª¨ìˆœ ë¶„ì„ ì™„ë£Œ: {len(contradictions)}ê°œ ëª¨ìˆœ ë°œê²¬")
                return contradictions
            except json.JSONDecodeError:
                logger.warning("AI ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•íƒœê°€ ì•„ë‹™ë‹ˆë‹¤.")
                return []
            
        except Exception as e:
            logger.error(f"AI ëª¨ìˆœ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _format_review_groups_for_analysis(self, review_groups: Dict) -> str:
        """ë¦¬ë·° ê·¸ë£¹ ë°ì´í„°ë¥¼ AI ë¶„ì„ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        formatted_text = ""
        
        group_names = {
            'positive_5': 'ê¸ì • ë¦¬ë·° (5ì )',
            'neutral_4_3': 'ì¤‘ë¦½ ë¦¬ë·° (4-3ì )',
            'negative_2_1': 'ë¶€ì • ë¦¬ë·° (2-1ì )'
        }
        
        for group_key, group_data in review_groups.items():
            group_name = group_names.get(group_key, group_key)
            formatted_text += f"\n### {group_name} ({group_data['review_count']}ê°œ ë¦¬ë·°)\n"
            
            # ì¥ì 
            if group_data['advantages']:
                formatted_text += "**ì¥ì :**\n"
                for adv in group_data['advantages']:
                    if isinstance(adv, dict) and 'point' in adv:
                        formatted_text += f"- {adv['point']}\n"
                        if 'details' in adv:
                            formatted_text += f"  ìƒì„¸: {adv['details']}\n"
            
            # ë‹¨ì 
            if group_data['disadvantages']:
                formatted_text += "**ë‹¨ì :**\n"
                for dis in group_data['disadvantages']:
                    if isinstance(dis, dict) and 'point' in dis:
                        formatted_text += f"- {dis['point']}\n"
                        if 'details' in dis:
                            formatted_text += f"  ìƒì„¸: {dis['details']}\n"
            
            formatted_text += "\n"
        
        return formatted_text
    
    def _get_contradiction_analysis_prompt(self) -> str:
        """ëª¨ìˆœ íƒì§€ìš© AI í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì œí’ˆ ê´‘ê³  ì‹ ë¢°ì„± í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œí’ˆì˜ ìƒì„¸ì •ë³´(ê´‘ê³ /ë§ˆì¼€íŒ… ë‚´ìš©)ì™€ ì‹¤ì œ ì†Œë¹„ì ë¦¬ë·°ë¥¼ ë¹„êµë¶„ì„í•˜ì—¬ ëª¨ìˆœì ì„ ì°¾ì•„ì£¼ì„¸ìš”.

ğŸ¯ ë¶„ì„ ëª©í‘œ: ê³¼ëŒ€ê´‘ê³  íƒì§€
- ìƒì„¸ì •ë³´ì—ì„œ ì£¼ì¥í•œ íš¨ê³¼/ê¸°ëŠ¥ì´ ì‹¤ì œ ë¦¬ë·°ì—ì„œ ë¶€ì •ì ìœ¼ë¡œ ì–¸ê¸‰ë˜ëŠ” ê²½ìš°
- ì œí’ˆì´ ì•½ì†í•œ ê²ƒê³¼ ì†Œë¹„ì ê²½í—˜ ê°„ì˜ ê²©ì°¨

ğŸ” ëª¨ìˆœ íƒì§€ ê¸°ì¤€:
1. **íš¨ëŠ¥/íš¨ê³¼ ëª¨ìˆœ**: ìƒì„¸ì •ë³´ íš¨ê³¼ ì£¼ì¥ vs ë¦¬ë·° "íš¨ê³¼ ì—†ìŒ"
2. **ì‚¬ìš©ê° ëª¨ìˆœ**: ìƒì„¸ì •ë³´ ì‚¬ìš©ê° ì£¼ì¥ vs ë¦¬ë·° ë¶ˆë§Œì¡±
3. **í’ˆì§ˆ ëª¨ìˆœ**: ìƒì„¸ì •ë³´ í’ˆì§ˆ ì£¼ì¥ vs ë¦¬ë·° í’ˆì§ˆ ë¬¸ì œ
4. **ê¸°ëŠ¥ ëª¨ìˆœ**: ìƒì„¸ì •ë³´ ê¸°ëŠ¥ ì£¼ì¥ vs ë¦¬ë·° ê¸°ëŠ¥ ë¶ˆë§Œ

ì‹¬ê°ë„ ê¸°ì¤€:
- **high**: ëª…í™•í•˜ê³  ì§ì ‘ì ì¸ ëª¨ìˆœ (íš¨ê³¼ ì£¼ì¥ vs íš¨ê³¼ ì—†ìŒ)
- **medium**: ê°„ì ‘ì ì´ì§€ë§Œ ì˜ë¯¸ìˆëŠ” ëª¨ìˆœ
- **low**: ì¼ë¶€ ë¶ˆë§Œì´ì§€ë§Œ ì‹¬ê°í•˜ì§€ ì•Šì€ ëª¨ìˆœ

ë‹¤ìŒ JSON í˜•íƒœë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
{
    "contradictions": [
        {
            "claim": "ìƒì„¸ì •ë³´ì—ì„œ ì£¼ì¥í•œ ë‚´ìš©",
            "reality": "ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì‹¤ì œ ê²½í—˜",
            "severity": "high/medium/low",
            "evidence": "ê·¼ê±°ê°€ ë˜ëŠ” ë¦¬ë·° ë‚´ìš©",
            "type": "íš¨ëŠ¥/ì‚¬ìš©ê°/í’ˆì§ˆ/ê¸°ëŠ¥"
        }
    ]
}

âš ï¸ ì¤‘ìš”: ëª…í™•í•œ ëª¨ìˆœë§Œ ë³´ê³ í•˜ì„¸ìš”. ë‹¨ìˆœí•œ ê°œì¸ì°¨ì´ë‚˜ ì• ë§¤í•œ ê²½ìš°ëŠ” ì œì™¸í•˜ì„¸ìš”."""
    
    def _calculate_penalty_score(self, contradictions: List[Dict]) -> float:
        """ëª¨ìˆœì— ë”°ë¥¸ ì ìˆ˜ ì°¨ê° ê³„ì‚° (100ì  ë§Œì  ê¸°ì¤€)"""
        penalty_mapping = {
            "high": 16.0,    # ì‹¬ê°í•œ ëª¨ìˆœ: 16ì  ì°¨ê° (5ì  ë§Œì ì—ì„œ 0.8ì  * 20)
            "medium": 8.0,   # ì¤‘ê°„ ëª¨ìˆœ: 8ì  ì°¨ê° (5ì  ë§Œì ì—ì„œ 0.4ì  * 20)
            "low": 4.0       # ê²½ë¯¸í•œ ëª¨ìˆœ: 4ì  ì°¨ê° (5ì  ë§Œì ì—ì„œ 0.2ì  * 20)
        }
        
        total_penalty = 0.0
        
        for contradiction in contradictions:
            severity = contradiction.get("severity", "low")
            penalty = penalty_mapping.get(severity, 4.0)
            total_penalty += penalty
            
            logger.debug(f"ëª¨ìˆœ ë°œê²¬: {contradiction.get('claim', 'N/A')} "
                        f"(ì‹¬ê°ë„: {severity}, ì°¨ê°: {penalty}ì )")
        
        # ìµœëŒ€ ì°¨ê° ì ìˆ˜ ì œí•œ (50ì )
        max_penalty = 50.0
        if total_penalty > max_penalty:
            logger.info(f"ì°¨ê° ì ìˆ˜ê°€ ìµœëŒ€ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: {total_penalty:.2f} -> {max_penalty}")
            total_penalty = max_penalty
        
        return total_penalty
    
    async def evaluate_product(self, product_id: int) -> Dict:
        """
        ì œí’ˆ ì¢…í•© í‰ê°€ ì‹¤í–‰
        
        Args:
            product_id: í‰ê°€í•  ì œí’ˆ ID
            
        Returns:
            ì „ì²´ í‰ê°€ ê²°ê³¼
        """
        try:
            logger.info(f"ì œí’ˆ ID {product_id} ì¢…í•© í‰ê°€ ì‹œì‘")
            
            # 1ë‹¨ê³„: ê°€ì¤‘í‰ê·  ì ìˆ˜ ê³„ì‚°
            weighted_score, calculation_details = self.calculate_weighted_score(product_id)
            
            if weighted_score == 0.0:
                logger.error(f"ì œí’ˆ ID {product_id}ì˜ ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨")
                return {"error": "ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨"}
            
            # 2ë‹¨ê³„: ëª¨ìˆœ íƒì§€ ë° ì ìˆ˜ ì°¨ê°
            contradictions, penalty_score = await self.detect_contradictions(product_id)
            
            # 3ë‹¨ê³„: 100ì  ë§Œì ìœ¼ë¡œ ë³€í™˜ ë° ìµœì¢… ì ìˆ˜ ê³„ì‚°
            weighted_score_100 = self._convert_to_100_scale(weighted_score)
            final_score_100 = max(0.0, weighted_score_100 - penalty_score)  # ìµœì†Œ 0ì 
            
            # í‰ê°€ ê²°ê³¼ ì •ë¦¬
            evaluation_result = {
                "product_id": product_id,
                "weighted_score_5": weighted_score,  # 5ì  ë§Œì  ì ìˆ˜ (ì°¸ê³ ìš©)
                "weighted_score": weighted_score_100,  # 100ì  ë§Œì  ì ìˆ˜
                "contradictions": contradictions,
                "penalty_score": penalty_score,
                "final_score": final_score_100,
                "calculation_details": calculation_details,
                "evaluation_summary": {
                    "total_contradictions": len(contradictions),
                    "score_improvement_from_base": final_score_100 - weighted_score_100,
                    "evaluation_grade": self._get_evaluation_grade(final_score_100)
                }
            }
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (100ì  ë§Œì ìœ¼ë¡œ ì €ì¥)
            evaluation_details_json = json.dumps(evaluation_result, ensure_ascii=False)
            save_success = save_product_evaluation(
                product_id=product_id,
                weighted_score=weighted_score_100,
                contradiction_penalties=penalty_score,
                final_score=final_score_100,
                evaluation_details=evaluation_details_json
            )
            
            if save_success:
                logger.info(f"ì œí’ˆ ID {product_id} í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
            else:
                logger.error(f"ì œí’ˆ ID {product_id} í‰ê°€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")
            
            logger.info(f"ì œí’ˆ ID {product_id} ì¢…í•© í‰ê°€ ì™„ë£Œ: {final_score_100:.1f}/100ì ")
            
            return evaluation_result
            
        except Exception as e:
            logger.error(f"ì œí’ˆ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    async def analyze_claims_vs_reality(self, product_id: int) -> Optional[Dict]:
        """
        ì œí’ˆ ìƒì„¸ì •ë³´ì˜ ë§ˆì¼€íŒ… ì£¼ì¥ê³¼ ì‹¤ì œ ì†Œë¹„ì ë¦¬ë·° ê°„ì˜ ì°¨ì´ì  ë¶„ì„
        
        Args:
            product_id: ë¶„ì„í•  ì œí’ˆ ID
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        try:
            logger.info(f"ì œí’ˆ ID {product_id}ì˜ ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ì‹œì‘")
            
            # 1. ì œí’ˆ ìƒì„¸ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            from .database import DB_FILE
            import sqlite3
            
            con = sqlite3.connect(DB_FILE)
            cur = con.cursor()
            cur.execute("SELECT detailed_summary FROM products WHERE id = ?", (product_id,))
            summary_result = cur.fetchone()
            con.close()
            
            if not summary_result or not summary_result[0]:
                logger.warning(f"ì œí’ˆ ID {product_id}ì˜ ìƒì„¸ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            product_summary = summary_result[0]
            
            # 2. ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            from .database import get_review_analysis_results
            review_results = get_review_analysis_results(product_id)
            
            if not review_results:
                logger.warning(f"ì œí’ˆ ID {product_id}ì˜ ë¦¬ë·° ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # 3. ìƒì„¸ì •ë³´ì—ì„œ ì£¼ìš” ì£¼ì¥ ì¶”ì¶œ
            import json
            try:
                # product_summaryëŠ” ë¬¸ìì—´ì´ë¯€ë¡œ ì§ì ‘ ì‚¬ìš©
                # ```json ìœ¼ë¡œ ê°ì‹¸ì§„ í˜•íƒœì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                summary_text = product_summary
                if summary_text.startswith('```json'):
                    # ```jsonê³¼ ```ë¥¼ ì œê±°í•˜ê³  JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    start_idx = summary_text.find('{')
                    end_idx = summary_text.rfind('}') + 1
                    if start_idx != -1 and end_idx != 0:
                        json_text = summary_text[start_idx:end_idx]
                        detailed_info = json.loads(json_text)
                    else:
                        raise json.JSONDecodeError("JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ", summary_text, 0)
                else:
                    # ì¼ë°˜ JSON ë¬¸ìì—´ë¡œ ì‹œë„
                    detailed_info = json.loads(summary_text)
            except (json.JSONDecodeError, IndexError) as e:
                logger.error(f"ì œí’ˆ ID {product_id}ì˜ ìƒì„¸ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.error(f"ë¬¸ì œê°€ ëœ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {product_summary[:200] if product_summary else 'None'}")
                return None
            
            # 4. ë¦¬ë·°ì—ì„œ ì¥ë‹¨ì  í†µí•©
            all_advantages = []
            all_disadvantages = []
            
            for result in review_results:
                _, _, sentiment_group, advantages_json, disadvantages_json, _, _ = result
                
                try:
                    advantages = json.loads(advantages_json) if advantages_json else []
                    disadvantages = json.loads(disadvantages_json) if disadvantages_json else []
                    
                    all_advantages.extend(advantages)
                    all_disadvantages.extend(disadvantages)
                except json.JSONDecodeError:
                    continue
            
            # 5. AIë¥¼ ì‚¬ìš©í•œ ëª¨ìˆœ ë¶„ì„
            analysis_result = await self._analyze_claims_vs_reality_with_ai(
                detailed_info, all_advantages, all_disadvantages
            )
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            from .database import save_claims_vs_reality_analysis
            save_success = save_claims_vs_reality_analysis(product_id, analysis_result)
            
            if save_success:
                logger.info(f"ì œí’ˆ ID {product_id}ì˜ ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ê²°ê³¼ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                logger.warning(f"ì œí’ˆ ID {product_id}ì˜ ë¶„ì„ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆì§€ë§Œ ê²°ê³¼ëŠ” ë°˜í™˜í•©ë‹ˆë‹¤.")
            
            logger.info(f"ì œí’ˆ ID {product_id}ì˜ ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ì™„ë£Œ")
            return analysis_result
            
        except Exception as e:
            logger.error(f"ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def _analyze_claims_vs_reality_with_ai(self, detailed_info: Dict, advantages: List, disadvantages: List) -> Dict:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆì¼€íŒ… ì£¼ì¥ê³¼ ì‹¤ì œ ë¦¬ë·° ê°„ì˜ ì°¨ì´ì  ë¶„ì„"""
        try:
            # ìƒì„¸ì •ë³´ì—ì„œ ì£¼ìš” ì£¼ì¥ ìš”ì•½
            product_claims = {
                "summary": detailed_info.get("product_summary", ""),
                "key_ingredients": detailed_info.get("key_ingredients", []),
                "benefits_claims": detailed_info.get("benefits_claims", []),
                "usage_instructions": detailed_info.get("usage_instructions", ""),
                "specifications": detailed_info.get("specifications", {})
            }
            
            # ë¦¬ë·°ì—ì„œ ì£¼ìš” í¬ì¸íŠ¸ ìš”ì•½
            review_points = {
                "advantages": [item.get("point", "") + ": " + item.get("details", "") for item in advantages if isinstance(item, dict)],
                "disadvantages": [item.get("point", "") + ": " + item.get("details", "") for item in disadvantages if isinstance(item, dict)]
            }
            
            prompt = f"""ë‹¹ì‹ ì€ ì œí’ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œí’ˆì˜ ë§ˆì¼€íŒ… ì£¼ì¥ê³¼ ì‹¤ì œ ì†Œë¹„ì ë¦¬ë·°ë¥¼ ë¹„êµí•˜ì—¬ ì°¨ì´ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ğŸ“‹ ì œí’ˆì˜ ë§ˆì¼€íŒ… ì£¼ì¥:
- ì œí’ˆ ìš”ì•½: {product_claims['summary']}
- ì£¼ìš” ì„±ë¶„: {', '.join(product_claims['key_ingredients']) if product_claims['key_ingredients'] else 'ì •ë³´ ì—†ìŒ'}
- íš¨ê³¼ ì£¼ì¥: {', '.join(product_claims['benefits_claims']) if product_claims['benefits_claims'] else 'ì •ë³´ ì—†ìŒ'}
- ì‚¬ìš©ë²•: {product_claims['usage_instructions']}

ğŸ—£ï¸ ì‹¤ì œ ì†Œë¹„ì ë¦¬ë·°:
ê¸ì •ì  í”¼ë“œë°±:
{chr(10).join('â€¢ ' + point for point in review_points['advantages'][:10]) if review_points['advantages'] else 'â€¢ ì—†ìŒ'}

ë¶€ì •ì  í”¼ë“œë°±:
{chr(10).join('â€¢ ' + point for point in review_points['disadvantages'][:10]) if review_points['disadvantages'] else 'â€¢ ì—†ìŒ'}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ë§ˆì¼€íŒ…ì—ì„œ ê°•ì¡°í•œ íš¨ê³¼ì™€ ì‹¤ì œ ì†Œë¹„ì ê²½í—˜ì˜ ì°¨ì´
2. ì˜ˆìƒê³¼ ë‹¤ë¥¸ ë¶€ì‘ìš©ì´ë‚˜ ë¬¸ì œì 
3. ì‚¬ìš©ë²•ì´ë‚˜ ê¸°ëŒ€ íš¨ê³¼ì˜ í˜„ì‹¤ì„±
4. ì „ë°˜ì ì¸ ì‹ ë¢°ë„ í‰ê°€

ë°˜ë“œì‹œ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "contradictions": [
        {{
            "claim": "ë§ˆì¼€íŒ…ì—ì„œ ì£¼ì¥í•œ ë‚´ìš©",
            "reality": "ì‹¤ì œ ì†Œë¹„ì ê²½í—˜",
            "severity": "ë†’ìŒ/ë³´í†µ/ë‚®ìŒ",
            "description": "êµ¬ì²´ì ì¸ ì°¨ì´ì  ì„¤ëª…"
        }}
    ],
    "consistency_points": [
        "ë§ˆì¼€íŒ… ì£¼ì¥ê³¼ ì¼ì¹˜í•˜ëŠ” ì ë“¤"
    ],
    "overall_assessment": "ì „ë°˜ì ì¸ í‰ê°€ (2-3ë¬¸ì¥)",
    "trust_level": "ë†’ìŒ/ë³´í†µ/ë‚®ìŒ"
}}"""

            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì œí’ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§ˆì¼€íŒ… ì£¼ì¥ê³¼ ì‹¤ì œ ë¦¬ë·°ë¥¼ ê°ê´€ì ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )
            
            result = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed_result = json.loads(result)
                logger.info("ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ì™„ë£Œ (ì§ì ‘ íŒŒì‹± ì„±ê³µ)")
                return parsed_result
            except json.JSONDecodeError:
                # ë°±ì—… íŒŒì‹± ë¡œì§
                try:
                    if "```json" in result:
                        json_start = result.find("```json") + 7
                        json_end = result.find("```", json_start)
                        if json_end != -1:
                            json_content = result[json_start:json_end].strip()
                            parsed_result = json.loads(json_content)
                            logger.info("ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ì™„ë£Œ (JSON ë¸”ë¡ ì¶”ì¶œ ì„±ê³µ)")
                            return parsed_result
                    
                    # ì¤‘ê´„í˜¸ ì¶”ì¶œ ì‹œë„
                    json_start = result.find("{")
                    json_end = result.rfind("}") + 1
                    if json_start != -1 and json_end > json_start:
                        json_content = result[json_start:json_end]
                        parsed_result = json.loads(json_content)
                        logger.info("ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ì™„ë£Œ (ì¤‘ê´„í˜¸ ì¶”ì¶œ ì„±ê³µ)")
                        return parsed_result
                        
                except json.JSONDecodeError:
                    pass
                
                logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜")
                return {
                    "contradictions": [],
                    "consistency_points": [],
                    "overall_assessment": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "trust_level": "ë³´í†µ",
                    "raw_response": result
                }
                
        except Exception as e:
            logger.error(f"AI ë§ˆì¼€íŒ… ì£¼ì¥ vs ì‹¤ì œ ë¦¬ë·° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "contradictions": [],
                "consistency_points": [],
                "overall_assessment": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "trust_level": "ë³´í†µ",
                "error": str(e)
            }
    
    def _convert_to_100_scale(self, score_5: float) -> float:
        """5ì  ë§Œì  ì ìˆ˜ë¥¼ 100ì  ë§Œì ìœ¼ë¡œ ë³€í™˜"""
        return (score_5 / 5.0) * 100.0
    
    def _get_evaluation_grade(self, score_100: float) -> str:
        """ì ìˆ˜ì— ë”°ë¥¸ í‰ê°€ ë“±ê¸‰ ë°˜í™˜ (100ì  ë§Œì  ê¸°ì¤€)"""
        if score_100 >= 90:
            return "A+ (ìš°ìˆ˜)"
        elif score_100 >= 80:
            return "A (ì¢‹ìŒ)"
        elif score_100 >= 70:
            return "B+ (ë³´í†µ ì´ìƒ)"
        elif score_100 >= 60:
            return "B (ë³´í†µ)"
        elif score_100 >= 50:
            return "C+ (ë¯¸í¡)"
        elif score_100 >= 40:
            return "C (ë¶€ì¡±)"
        else:
            return "D (ë§¤ìš° ë¶€ì¡±)"
    
    def get_evaluation_summary(self, product_id: int) -> Optional[Dict]:
        """íŠ¹ì • ì œí’ˆì˜ í‰ê°€ ìš”ì•½ ì¡°íšŒ"""
        try:
            evaluation_result = get_product_evaluation(product_id)
            
            if not evaluation_result:
                return None
            
            product_id, name, weighted_score, penalty, final_score, details, evaluated_at = evaluation_result
            
            try:
                details_parsed = json.loads(details) if details else {}
            except json.JSONDecodeError:
                details_parsed = {}
            
            return {
                "product_id": product_id,
                "product_name": name,
                "weighted_score": weighted_score,
                "penalty_score": penalty,
                "final_score": final_score,
                "grade": self._get_evaluation_grade(final_score),
                "contradictions_count": len(details_parsed.get("contradictions", [])),
                "evaluated_at": evaluated_at
            }
            
        except Exception as e:
            logger.error(f"í‰ê°€ ìš”ì•½ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def get_evaluation_stats(self) -> Dict:
        """ì „ì²´ í‰ê°€ í†µê³„ ì •ë³´"""
        try:
            evaluations = get_all_product_evaluations()
            
            if not evaluations:
                return {"message": "í‰ê°€ëœ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."}
            
            scores = [eval_data[4] for eval_data in evaluations]  # final_score
            
            stats = {
                "total_evaluated": len(evaluations),
                "average_score": sum(scores) / len(scores),
                "highest_score": max(scores),
                "lowest_score": min(scores),
                "grade_distribution": {},
                "top_products": []
            }
            
            # ë“±ê¸‰ ë¶„í¬ ê³„ì‚°
            for _, name, weighted, penalty, final, evaluated_at in evaluations:
                grade = self._get_evaluation_grade(final)
                stats["grade_distribution"][grade] = stats["grade_distribution"].get(grade, 0) + 1
                
                stats["top_products"].append({
                    "name": name,
                    "final_score": final,
                    "grade": grade
                })
            
            # ìƒìœ„ ì œí’ˆ ì •ë ¬ (ì ìˆ˜ ë†’ì€ ìˆœ)
            stats["top_products"].sort(key=lambda x: x["final_score"], reverse=True)
            stats["top_products"] = stats["top_products"][:5]  # ìƒìœ„ 5ê°œë§Œ
            
            return stats
            
        except Exception as e:
            logger.error(f"í‰ê°€ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}